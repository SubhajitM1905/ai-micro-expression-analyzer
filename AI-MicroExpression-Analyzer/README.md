# ğŸ§  AI Micro-Expression Analyzer

Real-time facial micro-expression analysis system that estimates **stress, hesitation, and emotional leakage** while a person speaks â€” powered by **MediaPipe Face Mesh (478 landmarks)** and **OpenCV**.

---

## âœ¨ Features

| Capability | How it works |
|---|---|
| **Eyebrow movement** | Tracks vertical distance between brow landmarks and upper eyelid anchor |
| **Lip tension** | Computes mouth width / height ratio; clenched lips â†’ high tension |
| **Blink rate** | Eye Aspect Ratio (EAR) per frame; counts blink events per minute |
| **Head micro-nods** | Frame-to-frame nose-tip Y delta normalized by head length |
| **Facial symmetry** | Left-cheek vs right-cheek distance to nose tip |

All five signals are fused with a weighted heuristic model to produce a single **stress score** mapped to three output levels:

| Level | Indicator |
|---|---|
| ğŸŸ¢ **Calm** | Score < 0.35 |
| ğŸŸ¡ **Slight Stress** | 0.35 â‰¤ Score < 0.65 |
| ğŸ”´ **High Stress / Possible Deception** | Score â‰¥ 0.65 |

---

## ğŸ“ Project Structure

```
AI-MicroExpression-Analyzer/
â”œâ”€â”€ __init__.py              # Package marker
â”œâ”€â”€ face_mesh_module.py      # MediaPipe FaceLandmarker wrapper & camera stream
â”œâ”€â”€ feature_engineering.py   # Extract 5 facial features from 478 landmarks
â”œâ”€â”€ stress_model.py          # Weighted heuristic stress estimator
â”œâ”€â”€ data_logger.py           # CSV session logger
â”œâ”€â”€ dashboard.py             # Terminal text dashboard
â”œâ”€â”€ main.py                  # Entry-point: OpenCV visual overlay + main loop
â””â”€â”€ face_landmarker.task     # MediaPipe model (downloaded at setup)
```

---

## ğŸš€ Quick Start

### 1. Clone the repo

```bash
git clone https://github.com/<your-username>/AI-MicroExpression-Analyzer.git
cd AI-MicroExpression-Analyzer
```

### 2. Create a virtual environment & install dependencies

```bash
python -m venv .venv
source .venv/bin/activate      # macOS / Linux
# .venv\Scripts\activate       # Windows

pip install mediapipe opencv-python numpy
```

### 3. Download the FaceLandmarker model

```bash
### 3. Download the FaceLandmarker Model (Required)

This project depends on the MediaPipe **Face Landmarker Task model**.

Download the file:

ğŸ‘‰ https://developers.google.com/mediapipe/solutions/vision/face_landmarker

OR directly:

https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/latest/face_landmarker.task

After downloading, place the file inside the project package directory:


```

### 4. Run the analyzer

```bash
# With live OpenCV window (default)
python -m ai_micro_expression.main


# With verbose terminal output
python -m ai_micro_expression.main --verbose
# Headless mode (terminal + CSV logging only)
python -m ai_micro_expression.main --no-display
```

Press **`q`** in the OpenCV window to quit.

---

## ğŸ–¥ï¸ OpenCV Live Dashboard

When running with display enabled you will see:

- **Left panel** â€” your live camera feed with 478 face-mesh landmark dots and a colour-coded border (green / amber / red)
- **Right panel** â€” dark sidebar showing:
  - Stress level banner with score
  - Progress bars for each metric (Eyebrow Raise, Lip Tension, Head Nod, Symmetry, Blink Rate)
  - Colour legend

---
---
## ğŸ“¸ Demo

<p align="center">
  <img src="assets/dashboard.png" width="800">
</p>



## âš™ï¸ CLI Options

| Flag | Default | Description |
|---|---|---|
| `--camera-index` | `0` | Camera device index |
| `--log-path` | `logs/session.csv` | Path for the CSV session log |
| `--no-display` | off | Disable the OpenCV window |
| `--verbose` | off | Print full metric breakdown to terminal |

---

## ğŸ“Š Data Logging

Every frame's metrics are appended to a CSV file (default `logs/session.csv`) with columns:

```
timestamp, eyebrow_raise, lip_tension, head_nod_intensity, symmetry_delta, blink_rate, stress_score
```

---

## ğŸ› ï¸ Tech Stack

- **Python 3.10+**
- **MediaPipe** (Tasks API â€” `FaceLandmarker`, 478 landmarks)
- **OpenCV** (camera capture + visual overlay)
- **NumPy** (vector math & signal smoothing)

---

## ğŸ“Œ Notes

- This is a **heuristic-based** system. It does **not** use a trained ML classifier for stress detection â€” it maps hand-crafted facial features to stress levels via weighted thresholds.
- The `face_landmarker.task` model file (~3.7 MB) is **not** committed to the repo. Download it using the curl command above.
- macOS users may need to grant **camera permission** to Terminal / VS Code.

---

## ğŸ“„ License

MIT â€” feel free to use, modify, and distribute.
